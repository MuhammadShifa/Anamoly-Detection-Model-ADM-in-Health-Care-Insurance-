{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Horovord with Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0xl0RrBhjzO7cwfFAAy2w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuhammadShifa/Horovod-with-Keras/blob/main/Horovord_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZcSxQDy5pyvC",
        "outputId": "6358ce9c-08f1-4ef5-cd49-8e63f49e3403"
      },
      "source": [
        "!pip install horovod"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting horovod\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/b2/9da3f1ad59a6d15263228e8e01ad3a4ee6c7233756abfb08813203ebaa11/horovod-0.21.0.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from horovod) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from horovod) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from horovod) (3.13)\n",
            "Requirement already satisfied: cffi>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from horovod) (1.14.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from horovod) (0.8)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.4.0->horovod) (2.20)\n",
            "Building wheels for collected packages: horovod\n",
            "  Building wheel for horovod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for horovod: filename=horovod-0.21.0-cp36-cp36m-linux_x86_64.whl size=21618615 sha256=da08c44ce4a650fdf36cdd3af316d0d5b61dae7389dff300f32d0d16ccb57206\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/0c/ea/6bd706effa600df0cc11074f75e5fd8dd2d66a979cb4ae5219\n",
            "Successfully built horovod\n",
            "Installing collected packages: horovod\n",
            "Successfully installed horovod-0.21.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8H8zqTZrwh-e",
        "outputId": "e07a14ac-bafd-40de-ec10-7505a9e3db16"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MrDEWvNaVa7"
      },
      "source": [
        "## Horovod with Keras MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-vw9EK0pubm",
        "outputId": "476b84a4-c579-41f7-bf8a-fe6b59a38887"
      },
      "source": [
        "import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras import backend as K\r\n",
        "import math\r\n",
        "import tensorflow as tf\r\n",
        "import horovod.keras as hvd\r\n",
        "\r\n",
        "# Horovod: initialize Horovod.\r\n",
        "hvd.init()\r\n",
        "\r\n",
        "# Horovod: pin GPU to be used to process local rank (one GPU per process), this code because we have tf v2\r\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "for gpu in gpus:\r\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\r\n",
        "if gpus:\r\n",
        "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n",
        "\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_classes = 10\r\n",
        "\r\n",
        "# Horovod: adjust number of epochs based on number of GPUs.\r\n",
        "epochs = int(math.ceil(12.0 / hvd.size()))\r\n",
        "\r\n",
        "# Input image dimensions\r\n",
        "img_rows, img_cols = 28, 28\r\n",
        "\r\n",
        "# The data, shuffled and split between train and test sets\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n",
        "    input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n",
        "    input_shape = (img_rows, img_cols, 1)\r\n",
        "\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "x_train /= 255\r\n",
        "x_test /= 255\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "\r\n",
        "# Convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\r\n",
        "                 activation='relu',\r\n",
        "                 input_shape=input_shape))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(num_classes, activation='softmax'))\r\n",
        "\r\n",
        "# Horovod: adjust learning rate based on number of GPUs.\r\n",
        "opt = keras.optimizers.Adadelta(1.0 * hvd.size())\r\n",
        "\r\n",
        "# Horovod: add Horovod Distributed Optimizer.\r\n",
        "opt = hvd.DistributedOptimizer(opt)\r\n",
        "\r\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=opt,\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "callbacks = [\r\n",
        "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\r\n",
        "    # This is necessary to ensure consistent initialization of all workers when\r\n",
        "    # training is started with random weights or restored from a checkpoint.\r\n",
        "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\r\n",
        "]\r\n",
        "\r\n",
        "# Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\r\n",
        "if hvd.rank() == 0:\r\n",
        "    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\r\n",
        "\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          batch_size=batch_size,\r\n",
        "          callbacks=callbacks,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1 if hvd.rank() == 0 else 0,\r\n",
        "          validation_data=(x_test, y_test))\r\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "  2/469 [..............................] - ETA: 2:04 - loss: 2.2968 - accuracy: 0.1152   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0054s vs `on_train_batch_end` time: 0.0464s). Check your callbacks.\n",
            "469/469 [==============================] - 13s 10ms/step - loss: 0.5446 - accuracy: 0.8282 - val_loss: 0.0607 - val_accuracy: 0.9809\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0966 - accuracy: 0.9710 - val_loss: 0.0426 - val_accuracy: 0.9867\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0691 - accuracy: 0.9790 - val_loss: 0.0310 - val_accuracy: 0.9893\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0525 - accuracy: 0.9846 - val_loss: 0.0298 - val_accuracy: 0.9898\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0459 - accuracy: 0.9862 - val_loss: 0.0264 - val_accuracy: 0.9912\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0424 - accuracy: 0.9881 - val_loss: 0.0283 - val_accuracy: 0.9906\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0363 - accuracy: 0.9884 - val_loss: 0.0266 - val_accuracy: 0.9913\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0335 - accuracy: 0.9898 - val_loss: 0.0247 - val_accuracy: 0.9915\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0301 - accuracy: 0.9911 - val_loss: 0.0295 - val_accuracy: 0.9913\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.0279 - val_accuracy: 0.9907\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0298 - val_accuracy: 0.9907\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0251 - accuracy: 0.9920 - val_loss: 0.0257 - val_accuracy: 0.9914\n",
            "Test loss: 0.025651391595602036\n",
            "Test accuracy: 0.9914000034332275\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9BCSN7Gac23"
      },
      "source": [
        "## Learning Step by Step Horovod"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3e1iJcsqjfW"
      },
      "source": [
        "import keras\r\n",
        "from keras.datasets import mnist\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Dropout, Flatten\r\n",
        "from keras.layers import Conv2D, MaxPooling2D\r\n",
        "from keras import backend as K\r\n",
        "import math\r\n",
        "import tensorflow as tf\r\n",
        "import horovod.keras as hvd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dl3eQi1rpJqL"
      },
      "source": [
        "# 1. Horovod: initialize Horovod.\r\n",
        "hvd.init()\r\n",
        "print(hvd.init())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9poikSgipQnI",
        "outputId": "5bd380d7-b7ec-4cf7-86b0-7522847f98e4"
      },
      "source": [
        "# 2. Horovod: pin GPU to be used to process local rank (one GPU per process), this code because we have tf v2\r\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\r\n",
        "for gpu in gpus:\r\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\r\n",
        "if gpus:\r\n",
        "    tf.config.experimental.set_visible_devices(gpus[hvd.local_rank()], 'GPU')\r\n",
        "\r\n",
        "print(\"The gpus is: \",gpus)\r\n",
        "print(\"The local rank is: \", hvd.local_rank())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The gpus is:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "The local rank is:  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5-ustdJpidJ",
        "outputId": "c9662f81-efd8-42c7-b79a-206325601991"
      },
      "source": [
        "batch_size = 128\r\n",
        "num_classes = 10\r\n",
        "\r\n",
        "# Horovod: adjust number of epochs based on number of GPUs.\r\n",
        "epochs = int(math.ceil(12.0 / hvd.size()))\r\n",
        "print(\"The size of hvd is: \", hvd.size())  #A function that returns the number of Horovod processes.\r\n",
        "print(\"The no of epoch is: \",epochs)\r\n",
        "\r\n",
        "# Input image dimensions\r\n",
        "img_rows, img_cols = 28, 28\r\n",
        "\r\n",
        "# The data, shuffled and split between train and test sets\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n",
        "    input_shape = (1, img_rows, img_cols)\r\n",
        "else:\r\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n",
        "    input_shape = (img_rows, img_cols, 1)\r\n",
        "\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "x_train /= 255\r\n",
        "x_test /= 255\r\n",
        "print('x_train shape:', x_train.shape)\r\n",
        "print(x_train.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')\r\n",
        "\r\n",
        "# Convert class vectors to binary class matrices\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\r\n",
        "                 activation='relu',\r\n",
        "                 input_shape=input_shape))\r\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
        "model.add(Dropout(0.25))\r\n",
        "model.add(Flatten())\r\n",
        "model.add(Dense(128, activation='relu'))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "model.add(Dense(num_classes, activation='softmax'))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The size of hvd is:  1\n",
            "The no of epoch is:  12\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtzxgTJcpp50",
        "outputId": "31f0110b-0a78-4baa-93e8-28a97295bd42"
      },
      "source": [
        "# 3. Horovod: adjust learning rate based on number of GPUs.\r\n",
        "opt = keras.optimizers.Adadelta(1.0 * hvd.size())\r\n",
        "\r\n",
        "# Horovod: add Horovod Distributed Optimizer.\r\n",
        "opt = hvd.DistributedOptimizer(opt)\r\n",
        "print(\"The hvd distributed optimizer is: \", opt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The hvd distributed optimizer is:  <horovod._keras.Adadelta object at 0x7f37577a1470>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0uQNvMpvVJ",
        "outputId": "2c5f2cfb-ecfb-4963-f562-114098a1e084"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\r\n",
        "              optimizer=opt,\r\n",
        "              metrics=['accuracy'])\r\n",
        "# 4. Synchronize state accross workers\r\n",
        "callbacks = [\r\n",
        "    # Horovod: broadcast initial variable states from rank 0 to all other processes.\r\n",
        "    # This is necessary to ensure consistent initialization of all workers when\r\n",
        "    # training is started with random weights or restored from a checkpoint.\r\n",
        "    hvd.callbacks.BroadcastGlobalVariablesCallback(0),\r\n",
        "]\r\n",
        "\r\n",
        "print(\"The callbacks is: \", callbacks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The callbacks is:  [<horovod.keras.callbacks.BroadcastGlobalVariablesCallback object at 0x7f37577a1390>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yjO8dPIp1yh",
        "outputId": "6816fd0b-6adf-4a41-9be0-c351ad56b4d9"
      },
      "source": [
        "# 5. Horovod: save checkpoints only on worker 0 to prevent other workers from corrupting them.\r\n",
        "if hvd.rank() == 0:\r\n",
        "    callbacks.append(keras.callbacks.ModelCheckpoint('./checkpoint-{epoch}.h5'))\r\n",
        "\r\n",
        "model.fit(x_train, y_train,\r\n",
        "          batch_size=batch_size,\r\n",
        "          callbacks=callbacks,\r\n",
        "          epochs=epochs,\r\n",
        "          verbose=1 if hvd.rank() == 0 else 0,\r\n",
        "          validation_data=(x_test, y_test))\r\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print('Test loss:', score[0])\r\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "  2/469 [..............................] - ETA: 2:05 - loss: 2.2947 - accuracy: 0.1309   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_train_batch_end` time: 0.0469s). Check your callbacks.\n",
            "469/469 [==============================] - 13s 10ms/step - loss: 0.5437 - accuracy: 0.8289 - val_loss: 0.0575 - val_accuracy: 0.9810\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0999 - accuracy: 0.9705 - val_loss: 0.0423 - val_accuracy: 0.9855\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0660 - accuracy: 0.9808 - val_loss: 0.0330 - val_accuracy: 0.9888\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0580 - accuracy: 0.9830 - val_loss: 0.0323 - val_accuracy: 0.9893\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0471 - accuracy: 0.9856 - val_loss: 0.0305 - val_accuracy: 0.9889\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0426 - accuracy: 0.9876 - val_loss: 0.0288 - val_accuracy: 0.9900\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0380 - accuracy: 0.9887 - val_loss: 0.0306 - val_accuracy: 0.9899\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0322 - accuracy: 0.9900 - val_loss: 0.0294 - val_accuracy: 0.9903\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0319 - accuracy: 0.9900 - val_loss: 0.0279 - val_accuracy: 0.9909\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0280 - accuracy: 0.9910 - val_loss: 0.0264 - val_accuracy: 0.9923\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 4s 9ms/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 0.0252 - val_accuracy: 0.9921\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 4s 8ms/step - loss: 0.0269 - accuracy: 0.9916 - val_loss: 0.0269 - val_accuracy: 0.9917\n",
            "Test loss: 0.026852218434214592\n",
            "Test accuracy: 0.9916999936103821\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}